import tensorflow as tf
import tensorflow.contrib.seq2seq as seq2seq
import os 
import csv
import numpy as np
import math
from tensorflow.python.ops.rnn_cell import LSTMCell
from tensorflow.python.ops.rnn_cell import MultiRNNCell
from tensorflow.python.ops.rnn_cell import RNNCell
from nltk.util import ngrams
from tensorflow.python.layers.core import Dense
from collections import Counter
from tensorflow.contrib.seq2seq.python.ops import attention_wrapper
from tensorflow.python.ops import embedding_ops
from tensorflow.python.util import nest


tf.reset_default_graph()

embedding_size = 32
sour_voc_size = 1000
targ_voc_size = 1000
max_time = 10
decoder_lengths = 20
max_sentence_length = 30


beam_size = 10
num_units = 128
batch_size = 80
hidden_size = 1000
with open('train.en.txt', encoding = 'utf-8') as f:
    source = str(f)
with open('train.de.txt', encoding = 'utf-8') as f:
    target = str(f)
source_list = " ".join(source).split()
source_list = list(set(source_list))
source_dict = {w: i for i, w in enumerate(source_list)}
word_to_idx = []
mode = {}
encoder_inputs  = []
decoder_inputs = []
#define encoder&decoder inputs
encoder_inputs = tf.placeholder(shape=(batch_size, max_time), dtype = tf.int32, name = 'encoder_inputs')
decoder_inputs = tf.placeholder(shape=(batch_size, max_time), dtype = tf.int32, name = 'decoder_inputs')
encoder_inputs_length = tf.placeholder(tf.int32, [batch_size], name = 'encoder_inputs_length')
decoder_inputs_length = tf.placeholder(tf.int32, [batch_size], name = 'decoder_inputs_length')
#embedding 
embedding_encoder = tf.Variable(tf.random_uniform([sour_voc_size, embedding_size], -1.0,
                                                  1.0), dtype = tf.float32)

'''
embedding_encoder = tf.Variable('embedding_encoder', [sour_voc_size, embedding_size])

'''

encoder_emb_imp = tf.nn.embedding_lookup(embedding_encoder, encoder_inputs)

embedding_decoder = tf.Variable(tf.random_uniform([targ_voc_size, embedding_size], -1.0,
                                                  1.0), dtype = tf.float32)
decoder_emb_imp = tf.nn.embedding_lookup(embedding_decoder, decoder_inputs)
max_target_sequence_length = tf.reduce_max(decoder_inputs_length, name='max_target_len')
#text process
def extract_character_voc(voc):
    #encoder rnn cell
#it uses bidirectional RNN, so the code could be written in this way:


lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)
lstm_fw_cwll = tf.nn.rnn_cell.DropoutWrapper(cell = lstm_fw_cell)
lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)
lstm_bw_cell = tf.nn.rnn_cell.DropoutWrapper(cell = lstm_bw_cell)

output, encoder_state = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, encoder_emb_imp, sequence_length=encoder_inputs_length, dtype = tf.float32)

output = tf.concat([output[0], output[1]], 2)
encoder_state  = tf.concat([encoder_state[1][0], encoder_state[1][1]], 1)
encoder_state = tf.expand_dims(encoder_state, 2)
    special_words = ['<PAD>', '<UNK>', '<GO>', '<EOS>']
    
    set_words = list(set([character for line in source.split('\n') for character in line]))
    # put these special words into the dictionary
    int_to_voc = {idx: word for idx, word in enumerate(special_words + set_words)}
    voc_to_int = {word: idx for idx, word in int_to_voc.items()}
    
    return int_to_voc, voc_to_int
    
    source_int_to_letter, source_letter_to_int = extract_character_voc(source)
    target_int_to_letter, target_letter_to_int = extract_character_voc(target)

    source_int = [[source_letter_to_int.get(letter, source_letter_to_int['<UNK>']) for letter in line]
                                          for line in source.split('\n')]
    target_int = [[target_letter_to_int.get(letter, target_letter_to_int['<UNK>']) for letter in line] 
                                    	    + [target_letter_to_int['<EOS>']] for line in target.split('\n')]
                                           
mask = tf.sequence_mask(decoder_inputs_length, max_target_sequence_length, dtype = tf.float32, name = 'masks')
with tf.variable_scope('decoder'):
    '''encoder_outputs = tf.contrib.seq2seq.tile_batch(encoder_outputs, multiplier = beam_size)
    encoder_state = nest.map_structure(lambda s: tf.contrib.seq2seq.tile_batch(s, beam_size), encoder_state)
    encoder_inputs_length = tf.contrib.seq2seq.tile_batch(encoder_inputs_length, multiplier = beam_size)
    '''
    encoder_inputs_length = encoder_inputs_length
    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units = num_units, memory = output,
                                                              memory_sequence_length = encoder_inputs_length)
    #decoder rnn cell & attention Wrapper
    
    decoder_cell = tf.nn.rnn_cell.LSTMCell(num_units = hidden_size)
    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(cell = decoder_cell, attention_mechanism = attention_mechanism,
                                                      attention_layer_size = num_units, name = 'Attention_Wrapper')
    
    
    #initialize the decoder, use encoder(ht)
    #ecoder_initial_state = decoder_cell.zero_state(batch_size=batch_size, dtype=tf.float32).clone(cell_state=encoder_state)
    projection_layer = tf.layers.Dense(targ_voc_size, kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev = 0.1))
    
    if mode == 'train':
        #define the inputs of the decoder, add beginning character and delete the ending character
        ending = tf.strided_slice(decoder_inputs, [0, 0], [batch_size, -1], [1, 1])
        decoder_input = tf.concat([tf.fill([batch_size, 1], word_to_idx['<GO>']), ending], 1)
        decoder_inputs_embedding = tf.nn.embedding_lookup(embedding, decoder_input)
        
        Training_helper = tf.contrib.seq2seq.TrainingHelper(inputs = decoder_inputs_embedding, 
                                                    sequence_length = encoder_inputs_length, time_major = False,
                                                    name = 'Training_helper')
        traing_decoder = tf.contrib.seq2seq.BasicDecoder(cell = decoder_cell, help = training_helper,
                                                         initial_state = encoder_state, output_layer = projection_layer)
        decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder = training_decoder, impute_finished = True,
                                                                 maximum_iterations = self.max_target_sequence_length)
        
        
    def seq2seq_model(input_data, rnn_size, num_layers, keep_prob, source_sequence_length, source_vocab_size,enc_embedding_size):
        train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1], num_units, num_layers,
                                                                       batch_size, max_target_sequence_length))
        train_logits = tf.identity(train_logits.rnn_output, 'logits')
        inference_logits = tf.identity(inference_logits.sample_id, name = 'prediction')
        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = decoder_inputs, logits = train_logits)
        
        loss = (tf.reduce_sum(cost*tf,stack(mask)) / (batch_size*decoder_inputs_length))
        global_step = tf.Variable(0)
        #staircase=True means that the learning_rate updates at discrete time steps
        learning_rate = tf.train.exponential_decay(10.0, global_step, 5000, 0.1, staircase=True)
        optimizer = tf.train.GradientDescentOptimizer(learning_rate)
        #optimizer = tf.train.AdadeltaOptimizer(learnnig_rate = learning_rate)
        gradients, v = zip(*optimizer.compute_gradients(loss))
        gradients, _ = tf.clip_by_global_norm(gradients, 25.0)
        optimize = optimizer.apply_gradients(zip(gradients, v))
    

        tf.summary.scalar('loss', self.loss)
        trainable_params = tf.trainable_variables()
        summary_op = tf.summary.merge_all()
        train_op = optimizer.apply_gradients(zip(gradients, trainable_params))
        
        '''
#It uses beamsearchdecoder in the paper, but if we want to use BasicDecoder, it needs helper
helper
Training_helper = tf.contrib.seq2seq.TrainingHelper(inputs = decoder_inputs_embedding, 
                                                    sequence_length = encoder_inputs_length, time_major = False,
                                                    name = 'Training_helper')
'''
    if mode == 'decode':
    
        batch_size = batch_size * beam_size
        start_tokens = tf.ones([batch_size, ], tf.int32) * word_to_idx['<GO>']
        end_token = word_to_idx['<EOS>']
        inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell = decoder_cell, embedding = embedding_decoder, 
                                                       start_tokens = start_tokens, end_token = end_tokens,
                                                       initial_state = decoder_initial_state, beam_width = beam_size,
                                                       output_layer = projection_layer)
        decoder_outputs,_,_ = tf.contrib.seq2seq.dynamic_decode(decoder = inference_decoder, impute_finished = True,
                                                        maximun_iteration = max_target_sequence_length)
        decoder_predict_decode = decoder_outputs.predict_ids
        
        keep_prob_placeholder =  1.0
#train
def train(sess, batch):
    
    feed_dict = {encoder_inputs, encoder_inputs_length,
                decoder_inputs, decoder_inputs_length,
                keep_prob_placeholder, batch_size}
    _, loss, summary = sess.run([train_op, loss, summary_op], feed_dict)
    return loss, summary
def eval(sess, batch):
    feed_dict = {encoder_inputs, encoder_inputs_length,
                keep_prob_placeholder, batch_size}
    loss, summary = sess.run([loss, summary_op], feed_dict)
    return loss, summary
def infer(sess, batch):
    feed_dict = {encoder_inputs, encoder_inputs_length,
                keep_prob_placeholder, batch_size}
    predict = sess.run([decoder_predict_decode], feed_dict)
    return predict
    
    vocab = open('vocab.50K.en.txt')
predict_seq = []
predict_ids = decoder_inputs_length * beam_size

def predict_to_seq(predict_ids, vocab, beam_size):
    for single_predict in predict_ids:
        for i in range(beam_size):
            predict_list = np.ndarray.tolist(single_predict[:, :, i])
            for idx in predict_list[0]:
                predict_seq.append(vocab[idx])
            print(predict_seq)
    
  
